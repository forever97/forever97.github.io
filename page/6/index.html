<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>未央の童话镇</title><meta name="keywords" content="forever97, 未央, 童话镇"><meta name="author" content="forever97"><meta name="copyright" content="forever97"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta property="og:type" content="website">
<meta property="og:title" content="未央の童话镇">
<meta property="og:url" content="https://forever97.top/page/6/index.html">
<meta property="og:site_name" content="未央の童话镇">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/avatar.png">
<meta property="article:author" content="forever97">
<meta property="article:tag" content="forever97, 未央, 童话镇">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/avatar.png"><link rel="shortcut icon" href="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/favicon.png"><link rel="canonical" href="https://forever97.top/page/6/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="baidu-site-verification" content="f7c8ecf684c23d02cca2e82c827ff2a2"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?194bd025765eb0d478283a5eb4217ad4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: forever97","link":"链接: ","source":"来源: 未央の童话镇","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-06-26 06:44:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}const fontSizeVal = saveToLocal.get('global-font-size')
if (fontSizeVal !== undefined) {
  document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
}})()</script><link rel="stylesheet" href="/gitcalendar/css/gitcalendar.css"/><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="/magnet/css/catalogMagnet.css"/><link rel="stylesheet" href="/swiper/swiper.min.css"><link rel="stylesheet" href="/swiper/swiperstyle.css"><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">149</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">122</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 博客</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-20px;"><li><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></li><li><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 链接</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-60px;"><li><a class="site-page" href="/moments/"><i class="fa-fw fas fa-user-circle"></i><span> 朋友圈</span></a></li><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> 友人帐</span></a></li><li><a class="site-page" href="/website/"><i class="fa-fw fas fa-th-large"></i><span> 百宝箱</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-60px;"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 镜像</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px;"><li><a class="site-page" href="https://forever97.top/"><i class="fa-fw fab fa-vimeo"></i><span> Vercel</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.gitee.io/"><i class="fa-fw fab fa-google"></i><span> Gitee</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.github.io/"><i class="fa-fw fab fa-github"></i><span> Github</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.netlify.app/"><i class="fa-fw fab fa-tripadvisor"></i><span> Netlify</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-info-circle"></i><span> 关于</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-20px;"><li><a class="site-page" href="/site/"><i class="fa-fw fas fa-sitemap"></i><span> 本站</span></a></li><li><a class="site-page" href="/me/"><i class="fa-fw fas fa-id-badge"></i><span> 本人</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/welcome-cover.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">未央の童话镇</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 博客</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-20px;"><li><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></li><li><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 链接</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-60px;"><li><a class="site-page" href="/moments/"><i class="fa-fw fas fa-user-circle"></i><span> 朋友圈</span></a></li><li><a class="site-page" href="/link/"><i class="fa-fw fas fa-address-book"></i><span> 友人帐</span></a></li><li><a class="site-page" href="/website/"><i class="fa-fw fas fa-th-large"></i><span> 百宝箱</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-60px;"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 镜像</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px;"><li><a class="site-page" href="https://forever97.top/"><i class="fa-fw fab fa-vimeo"></i><span> Vercel</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.gitee.io/"><i class="fa-fw fab fa-google"></i><span> Gitee</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.github.io/"><i class="fa-fw fab fa-github"></i><span> Github</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://forever97.netlify.app/"><i class="fa-fw fab fa-tripadvisor"></i><span> Netlify</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-info-circle"></i><span> 关于</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-20px;"><li><a class="site-page" href="/site/"><i class="fa-fw fas fa-sitemap"></i><span> 本站</span></a></li><li><a class="site-page" href="/me/"><i class="fa-fw fas fa-id-badge"></i><span> 本人</span></a></li></ul></div></div></div><div id="rightmenu" style="flex:1"><div id="search-button" style="position:absolute;right:2%"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">未央の童话镇</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/forever97" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://gitee.com/forever97/" target="_blank" title="Gitee"><i class="fab fa-google"></i></a><a class="social-icon" href="https://www.cnblogs.com/forever97" target="_blank" title="博客园"><i class="fas fa-blog"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=857426255&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:857426255@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item photo-tag" style="width:100%;height:auto;float:left;padding:5px;flex-wrap:wrap;justify-content:center;flex-direction:row;"><div id="catalogMagnet"><figure class="gallery-group color-card" v-for="(item,index) in link" :style="[figbackColor,figShadow]"><img class="gallery-group-img loaded" :src="img[index]" data-ll-status="loaded"><figcaption :style="[figLetimg,figLetColor]"><div class="gallery-group-name magnetname" style="font-size: 1rem;"><span>| </span><a :href="catalogMagnet.link[index]" :style="[figLetColor]">{{catalogMagnet.link[index].text}}</a></div><li class="category-list-item"><span class="category-list-count"><i class="fas fa-book"></i>{{catalogMagnet.postnum[index].textContent}}</span></li><p>{{catalogMagnet.describe[index]}}</p><a :href="catalogMagnet.link[index]"></a></figcaption></figure></div><div class="categoryMagnetitem" style="display:none"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E2%9C%A8%E9%A2%98%E8%A7%A3%E6%9D%82%E8%B4%A7%E9%93%BA/">✨题解杂货铺</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E2%AD%90OD%E6%91%98%E6%98%9F%E6%A5%BC/">⭐OD摘星楼</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8C%99VUE%E6%A2%A6%E5%B7%A5%E5%8E%82/">🌙VUE梦工厂</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8C%BACSS%E8%8A%B1%E5%B8%82/">🌺CSS花市</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8D%AD%E7%AE%97%E6%B3%95%E5%B9%BC%E5%84%BF%E5%9B%AD/">🍭算法幼儿园</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8D%B0HTML%E7%82%B9%E5%BF%83%E9%93%BA/">🍰HTML点心铺</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8D%B5D3%E8%8C%B6%E6%A5%BC/">🍵D3茶楼</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8D%BABLOG%E9%85%92%E8%82%86/">🍺BLOG酒肆</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8E%A8React%E6%9F%93%E5%9D%8A/">🎨React染坊</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8E%AAGAN%E9%A9%AC%E6%88%8F%E5%9B%A2/">🎪GAN马戏团</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%8E%B5Canvas%E4%B9%90%E5%9D%8A/">🎵Canvas乐坊</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%92%84VIS%E8%83%AD%E8%84%82%E9%93%BA/">💄VIS胭脂铺</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a><span class="category-list-count">28</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%94%AC%E7%88%AC%E8%99%AB%E7%A0%94%E7%A9%B6%E6%89%80/">🔬爬虫研究所</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%F0%9F%A7%B8JS%E7%8E%A9%E5%85%B7%E5%B1%8B/">🧸JS玩具屋</a><span class="category-list-count">6</span></li></ul></div></div><div class="recent-post-item" style="height:0px;clear:both;margin-top: 0px;border: 0px;"></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/30/CCVQA/" title="CC-VQA [循环一致性]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/CCVQA-2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CC-VQA [循环一致性]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/30/CCVQA/" title="CC-VQA [循环一致性]">CC-VQA [循环一致性]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-30T09:06:51.000Z" title="发表于 2020-07-30 09:06:51">2020-07-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2019/">2019</a></span></div><div class="content">Paper Download Address
已有的工作研究了VQA模型对图像中有意义的语义变化的鲁棒性和敏感性，改变答案分布和对图像攻击，但是没有对问题语法变化的研究，问题形式变化对VQA model的能力(VQA系统是否真的理解了问题)以及应用程序(用户会用不同的语言形式来提问)角度来说都是非常重要的，但是目前SOTA模型对问题语言的变化是十分脆弱的

作者提出了一个循环一致性(cycle consistency)的框架，训练模型在回答问题的基础上还要生成形式不同但是语义相同的问题变体，要求生成的问题预测的答案与原始问题的ground truth答案相匹配
这个训练框架有两个优点，一是提高了模型在测试集问题形式变化时的泛化的能力，二是模型可学习的bias减少了，因为一个要同时完成问题生成和问题回答任务的模型不太容易利用语言先验以及走捷径
为了能够定量评估VQA模型在输入问题中的语言变异的鲁棒性和一致性，作者收集了一个大规模数据集VQA-Rephrasings，并在该数据集上测试了SOTA模型，实现表明VQA模型对问题语言表示变化的脆弱性，这说明现有的VQA模型并不能充分理解语言，用 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/29/DFAF/" title="DFAF [动态模内模间注意流]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/DFAF-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DFAF [动态模内模间注意流]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/29/DFAF/" title="DFAF [动态模内模间注意流]">DFAF [动态模内模间注意流]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-29T18:28:58.000Z" title="发表于 2020-07-29 18:28:58">2020-07-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/attention/">attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2019/">2019</a></span></div><div class="content">Paper Download Address
VQA模型性能的提升得益于三个方面，一是更好的视觉和语言特征表示，二是注意力机制，三是更好的多模态融合方法
目前的VQA模型大多在学习视觉和语言特征之间的跨模态关系(inter-modality relations)，Bilinear feature fusion主要通过特征的外积来获取语言和视觉模式之间的高阶关系，Co-attention和bilinear attentionbasedapproaches通过学习词区域对(word-region pairs)之间的跨模态关系来完成VQA任务
此外也有学习模态内部关系(intra-modality relations)的方法，Hu et al提出探索模内对象-对象关系，以提高目标检测精度，Yao et al学习模内对象-对象关系，以提高图像字幕性能，BERT采用自注意机制对模内词关系进行建模，得到了SOTA的word embedding，
在解决VQA问题的框架中从未同时研究过模内关系和跨模关系，作者认为被大多数VQA系统忽略的模内关系是跨模关系的补充，每个图像区域不仅要从问题中的关联词/短 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/29/count/" title="Count模块源码解读">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/count-5.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Count模块源码解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/29/count/" title="Count模块源码解读">Count模块源码解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-29T07:32:55.000Z" title="发表于 2020-07-29 07:32:55">2020-07-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2018/">2018</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/count/">count</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/code/">code</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/ICLR/">ICLR</a></span></div><div class="content">Code Download Address
Paper Record
计数的基本方法是确定边的数量，通过子图完全图边和点的关系来计算点数，最后得到答案
top n bounding box首先处理出处理出top n的注意力权重和对应的bounding box
123456def filter_most_important(self, n, boxes, attention):    &quot;&quot;&quot; Only keep top-n object proposals, scored by attention weight &quot;&quot;&quot;    attention, idx = attention.topk(n, dim=1, sorted=False)    idx = idx.unsqueeze(dim=1).expand(boxes.size(0), boxes.size(1), idx.size(1))    boxes = boxes.gather(2, idx)    return boxes, attention

boxes的sha ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/28/learningToCount/" title="Learning To Count [VQA计数]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/learningToCount-0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning To Count [VQA计数]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/28/learningToCount/" title="Learning To Count [VQA计数]">Learning To Count [VQA计数]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-28T07:50:34.000Z" title="发表于 2020-07-28 07:50:34">2020-07-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2018/">2018</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/count/">count</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/ICLR/">ICLR</a></span></div><div class="content">Paper Download Address

想要统计图中有几只猫通常需要这样几个步骤：理解实例的视觉表现，在图中找到实例以及计数

这在VQA中是一个常见的Task，然而目前的VQA系统在数据集bias之外的情况很难回答计数问题，主要原因是广泛使用的软注意力机制以及VQA中的计数并不像标准计数对计数目标有GT标定
模型需要能够对大量对象进行计数，并且在理想情况下，在非计数问题上的性能不受到损害，因此非常具有挑战性
为了简化这个task，作者采用object proposals，即将目标检测得到的bounding box和对应的对象特征作为输入而非从pixel层面学习。在复杂的场景中，通常会遇到重复计算重叠对象的问题，这是一个存在于许多自然图像中的问题，它会导致在真实场景中不准确的计数
文章的主要贡献是提出了一个可微的神经网络组件来完成计数，该组件与注意机制一起使用，避免了软注意的基本限制，同时产生强大的计数功能，实验表明，使用计数组件的相对简单的基线模型优于所有以前的模型，而不会降低其他类别的性能
RELATED WORKgreedy non-maximum suppression ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/27/whereToLook/" title="Where To Look [注意力机制]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/whereToLook-2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Where To Look [注意力机制]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/27/whereToLook/" title="Where To Look [注意力机制]">Where To Look [注意力机制]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-27T07:27:22.000Z" title="发表于 2020-07-27 07:27:22">2020-07-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/attention/">attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2016/">2016</a></span></div><div class="content">Paper Download Address
这篇文章主要致力于解决VQA和其它一些视觉推理问题中的一个核心任务：knowing where to look

如图所示，若红绿灯能够成功被定位，则可以轻易回答问题”What color is the walk light”，如何能够定位到雨伞，则有利于回答”Is it raining”，模型需要学习到被期待的答案的类型，以及做出回答需要基于图片的哪部分
where to look的实现是具有挑战性的，有些问答需要利用全图，而有些回答则需要关注特定的区域，文章中忽略需要额外知识辅助回答和需要推理回答的问题(比如图中男女在约会么)
作者的key idea是学习一个非线性映射，将图片和问题投射到相同的latent space来确定它们之间的关联，然后对相关区域和QA对的匹配度打分，latent space和打分函数由用QA对监督的margin-based loss来共同学习
文章主要的贡献为：

提出了一个图像区域选择机制，学习识别问题相关的图像区域

提出了一个采用margin-based loss的VQA多选题的学习框架，明显优于base ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/23/BUTD1/" title="Tips and Tricks for Visual Question Answering">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/BUTD1-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Tips and Tricks for Visual Question Answering"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/23/BUTD1/" title="Tips and Tricks for Visual Question Answering">Tips and Tricks for Visual Question Answering</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-23T07:50:12.000Z" title="发表于 2020-07-23 07:50:12">2020-07-23</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2018/">2018</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/attention/">attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a></span></div><div class="content">Paper Download Address
这篇文章提出了一个相对简单的VQA模型，达到了SOTA的效果，文章的核心目的是分享一个成功的VQA模型的细节
model首先得到问题和图片的联合嵌入(joint embedding)，随后是针对一组候选答案的多标签分类器，这种通用方法是现在很多VQA模型的基础，模型的细节对于获得高质量的结果至关重要
同时作者在模型上采用了一些关键的技术创新，极大提高了模型的表现，作者在探索模型空间结构和超参数上进行了大量的实验，以确定每个组件的重要性
主要发现概括如下
—— 使用sigmoid输出，允许每个问题有多个正确答案，而不是一个常见的单标签softmax
—— 使用软分数作为GT目标，使得task为候选答案分数的回归，而不是传统的分类
—— 对所有非线性层使用gated tanh激活函数
—— 采用bottom-up注意力得到的图片特征，自底向上注意力提供的是特定区域的特征，而非CNN传统的网格特征图
—— 使用预先训练好的候选答案表示来初始化输出层的权重
—— 在随机梯度下降的训练过程中对训练数据采用较大的mini-batches，以及智能打乱( ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/20/ESTVQA/" title="EST-VQA [双语文本VQA]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/ESTVQA-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EST-VQA [双语文本VQA]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/20/ESTVQA/" title="EST-VQA [双语文本VQA]">EST-VQA [双语文本VQA]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-20T07:27:09.000Z" title="发表于 2020-07-20 07:27:09">2020-07-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/dataset/">dataset</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/TextVQA/">TextVQA</a></span></div><div class="content">Paper Download Address
对数据集中的巧合相关性的学习使得VQA系统难以泛化，巧合相关性在数据集中并不稳定，当测试集中的分布与训练集不同时，基于巧合相关性所学习到的东西就不再work
泛化VQA存在的一个潜在问题就是无法判断正确答案是否由正确的理由产生，通过推理得到的答案和通过巧合相关性得到的答案表面上是完全一致的
文章中提出一种度量VQA性能的方法，它通过要求算法证明其推理的合理性来鼓励泛化

之前也有相关工作研究过推理过程，但是因为提供理由的形式是有限的而饱受困扰，文章中的方法是提供一个简单的指示，说明它的答案是基于图像的哪个区域，若VQA系统提供了正确的答案和正确的图像区域，则说明其推理过程是正确的
作者在Scene Text VQA上做测试，选择这种测试集的原因是大部分VQA model在Text VQA数据集上表现不佳，但是图片中的文本对图片的理解往往是很有指示意义的，而且文本VQA问题通常不太容易通过利用数据中的巧合相关性来解决
同时，因为文本VQA图像中出现的文本范围十分广泛，因此基于分类的方法很容易过拟合，需要开发替代方法，并且这些方法可以推广到其它 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/17/SE/" title="Squeeze-and-Excitation Networks">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/SE-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Squeeze-and-Excitation Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/17/SE/" title="Squeeze-and-Excitation Networks">Squeeze-and-Excitation Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-17T07:11:11.000Z" title="发表于 2020-07-17 07:11:11">2020-07-17</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/2018/">2018</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/attention/">attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a></span></div><div class="content">Paper Download Address
在卷积网络的每一层，一些卷积核沿着输入通道方向表示相邻特征模式，在局部感受野(local receptive fields)的范围内融合空间及channel-wise特征信息。通过交错的组合卷积，下采样，非线性层等构建网络，CNN可以达到理论上的全局感受野(global theoretical receptive fields)，以捕获图像的特征来进行图像的描述。最近的研究表明，将集成学习机制整合到CNN中可以提高网络的表示能力，Inception结构中嵌入了多尺度信息，聚合多种不同感受野上的特征来获得性能增益，还有进一步的工作是寻求更好地模拟空间依赖性，并将空间注意纳入网络的结构
文章跟以往的网络结构均不同，研究的是通道(channel)之间的关系。文章中提出了一种机制，允许网络执行特征重新标定，通过这种机制，网络可以学会使用全局信息，有选择地强调信息特征，抑制不太有用的特征

给定输入X，通过一系列的卷积操作变成特征通道数为C的U，执行Squeeze操作，顺着空间维度进行特征压缩，将每个二维的特征通道变为一个实数，这个实数在某种程度上具 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/15/BUTD/" title="BUTD注意力机制">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/BUTD-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="BUTD注意力机制"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/15/BUTD/" title="BUTD注意力机制">BUTD注意力机制</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-15T07:34:28.000Z" title="发表于 2020-07-15 07:34:28">2020-07-15</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2018/">2018</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/attention/">attention</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/image-captioning/">image captioning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a></span></div><div class="content">Paper Download Address
在图像字幕和VQA中使用的大多数传统视觉注意机制都是自顶而下的，这些机制通常被训练成有选择地关注CNN的一个或多个层的输出，然而这种方法很少确定图像的关注区域

传统的CNN网络在引入注意力机制的时候，图像区域会分成大小均一的网格(左图)，为了生成更像人类的字幕和问题答案，要将注意力自然地放在物体和其他突出的图像区域上，因此文章中提出的注意力机制是对象层面的(右图)
文章提出了一种结合自顶向下和自底向上的注意力机制，自底向上采用Faster R-CNN模型处理显著图像区域，每个区域由一个池化卷积特征向量表示，自顶向下采用task-specific来预测注意力区域，将其特征作为所有区域的图像特征的权重
相关工作在VQA和图像字幕领域产生了大量基于注意力机制的深度神经网络，这些模型可以被归类为自顶向下的方法，注意力机制被应用于CNN的一个或多个层的输出。然而，确定图像区域的最佳数目总是需要在不同细节层次之间进行权衡，此外，与图像内容相关的区域的任意定位可能会导致检测到与区域不一致的物体，且将同一物体相关的视觉概念结合起来会变得更加困难
相对而来 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/14/VCRCNN/" title="VC R-CNN [将常识引入特征]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/VCRCNN-2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VC R-CNN [将常识引入特征]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/14/VCRCNN/" title="VC R-CNN [将常识引入特征]">VC R-CNN [将常识引入特征]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-14T07:06:28.000Z" title="发表于 2020-07-14 07:06:28">2020-07-14</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/debias/">debias</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/feature-extraction/">feature extraction</a></span></div><div class="content">Paper Download Address
现今的计算机视觉系统擅于告诉我们”什么”，”哪里”，但并不擅长告诉我们”为什么”，这个”为什么”指的就是视觉原因，缺乏常识很容易导致机器学习中的认知误差，比如和leg区域相比，有更多的person区域和ski单词一同出现，那么视觉注意力会更多地放在人身上，但如果我们拥有”常识性”的特征，看到ski的时候我们就会把注意力集中到脚上

常识并不总是包含在语言中的(因为有reporting bias)，比如我们会看到”人在路上走”，但应该很少见到”人用脚走路”。NLP中词X可以通过预测上下文中的Y来学习，但是这种做法很难迁移到图像中，因为图像中对象同现的显式原因无法被观察到，那么导致X和Y同现的真正常识会被observational bias混淆，比如如果键盘和鼠标总是被观察到在桌子上，那么得到的常识可能是键盘和鼠标是桌子的一部分而非电脑
文章利用MS-COCO数据集中的标注信息，计算Association P(Y|X)和Intervention P(Y|do(X))之间的区别，这里可以简单地理解为1.从别的图片”bollow”一个对象Z；2.将 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/09/SQuINTing/" title="SQulNTing [子问题一致性]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/SQulNTing-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SQulNTing [子问题一致性]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/09/SQuINTing/" title="SQulNTing [子问题一致性]">SQulNTing [子问题一致性]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-09T07:59:19.000Z" title="发表于 2020-07-09 07:59:19">2020-07-09</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/dataset/">dataset</a></span></div><div class="content">Paper Download Address
VQA问题要求模型在多个抽象层面进行推理，比如要回答问题”这个香蕉熟到能吃的地步了么”，VQA model需要检测香蕉并且提取它的相关属性比如大小和颜色。抽象概念是复杂，多细节层次的。
文章中将问题分为感知和推理两类，感知问题只要求对对象确认存在，查询对象的物理属性和判断对象之间的空间关系，比如”图中香蕉是什么颜色的”或者”这个人的左边的是什么”，推理问题则需要结合视觉感知，逻辑和先验知识来完成，比如”这个香蕉熟到能吃的地步了么”
将问题划分为感知和推理可以更好地评估模型的视觉感知和高级推理能力，作者认为，将感知问题作为推理问题的子任务是有帮助的。通过阐述这样的子任务，可以检测模型是通过合理推断还是通过数据集中的bias和捷径来得到答案。就比如，我们需要留意一下模型的推理能力当其对于香蕉的颜色答案为黄，但对于香蕉能否食用答案是否的时候。高水平推理任务与低水平感知任务之间的不一致表明model还没有有效地学习如何回答推理问题。这些子问题可以用来对任何VQA模型评估而不仅是那些被用来提供理由的模型
随着推理问题的复杂化，目前使用的方法实现良好的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/08/GQAOOD/" title="GQA-OOD [低频样本处理]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/GQAOOD-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GQA-OOD [低频样本处理]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/08/GQAOOD/" title="GQA-OOD [低频样本处理]">GQA-OOD [低频样本处理]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-08T08:01:56.000Z" title="发表于 2020-07-08 08:01:56">2020-07-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/dataset/">dataset</a></span></div><div class="content">Paper Download Address
玫瑰是红色的，紫罗兰是蓝色的，但是，VQA系统理应期待他们是这样的么？
目前多数的VQA数据集仍然非常的不平衡，大量常用的表述比如红玫瑰，与上下文无关的表述比如城市中的斑马，这些表述导致模型过分依赖于biases，缺乏一般化的能力。尽管对这个问题有普遍的共识，对误差分布的系统性评估仍然非常稀缺。整体正确率依然是主流，甚至唯一的评判依据，虽然这是不合理的。
现在对于模型的评判有这些问题：误差分布是什么样的？正确的预测是因为推理还是因为偏见？在低频样本和高频样本上的正确率如何？如何在分布之外(OOD)验证模型？
文章提出了一种新的标准，这个标准包含

一个重新组合的GQA数据集，在验证集和测试集中引入分布变换
一系列评估方法
新的评价图来说明VQA在不同操作点上的推理行为

选择GQA数据集是因为其问题组结构能够捕捉biases，可以以此来选择具有较强偏见的组并创建分布转换，为每一个问题添加约束

作者用这个标准做了大量的实验发现许多SOTA VQA模型都不能胜任解决不常见问题的工作，同时在VQA降低偏见的方法上得到同样的结论。
仅在高频样本上 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/07/generatingRationales/" title="为VQA生成原因">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/generatingRationales-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="为VQA生成原因"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/07/generatingRationales/" title="为VQA生成原因">为VQA生成原因</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-07T08:10:00.000Z" title="发表于 2020-07-07 08:10:00">2020-07-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/rationales-generation/">rationales generation</a></span></div><div class="content">Paper Download Address
想要在VQA任务中有突出的表现，model必须理解问题并找到问题相关答案的能力，有个严肃的问题是这些model在预测答案的时候到底能够理解image，question和answer到一个什么程度，它们是否只是利用了问题，图片或者答案中的biases
衡量模型对三个方面(questions, images, answers)的理解能力并不是一个主流工作，之前相关工作有对word进行微扰，检查视觉热力图等，文章希望做的是对三个方面做一个联合，同时测试模型语言和视觉模块
为了完成这一点，文章为VQA系统提出了一个novel task，不仅要理解问题(linguistic modality)，理解图片(visual modality)，同时也要为预测的答案提供理由，指出其和图片以及问题的关系
作者采用VCR(Visual Commonsense Reasoning)数据集，该数据集中包含图片，问题，对应的四个候选答案，和四个原因选项，作者用VQA系统选择答案，然后对答案生成原因，对比真实原因来评估model的综合理解能力
作者用这个方法测试了VCR ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/03/DLR/" title="通过分解语言表征来克服VQA中的语言先验">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/DLR-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="通过分解语言表征来克服VQA中的语言先验"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/03/DLR/" title="通过分解语言表征来克服VQA中的语言先验">通过分解语言表征来克服VQA中的语言先验</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-03T20:58:39.000Z" title="发表于 2020-07-03 20:58:39">2020-07-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/debias/">debias</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/AAAI/">AAAI</a></span></div><div class="content">Paper Download Address
目前多数VQA model中存在语言先验(Language Priors)问题，比如对于颜色会快速回答”white”，对于运动会快速回答”tennis”，对于”is there a”开头的问题会快速回答”yes”，这些模型并不能真正辨别问题中信息的不同之处，他们只是利用答案和询问词(interrogative words)的同现性来得到答案
尽管有些模型采用了问题注意力机制，将关键词和视觉信息结合，但是它们并没有消除interrogative words的影响，因此仍存在language prior
[1]的研究中，为了消除language piror，用多个手工设计的模块来处理问题中不同的信息，他们用一个问题分类器将问题划分为yes/no类别和非yes/no类别，用一种基于词性的概念抽取器来提取yes/no问题中的概念，以及答案聚类预测因子确定非yes/no问题的答案类型
[1] Agrawal, A.; Batra, D.; Parikh, D.; and Kembhavi, A. 2018. Dont just assume; loo ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/07/02/CSSVQA/" title="CSS-VQA [反事实]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/CSSVQA-2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CSS-VQA [反事实]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/02/CSSVQA/" title="CSS-VQA [反事实]">CSS-VQA [反事实]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-02T16:06:11.000Z" title="发表于 2020-07-02 16:06:11">2020-07-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CVPR/">CVPR</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/counterfactual/">counterfactual</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2020/">2020</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/debias/">debias</a></span></div><div class="content">Paper Download Address
由于数据集的问题，目前很多VQA模型仍然过于依赖language biases，比如一个对于”how many X”问题只会回答2的模型可以依然得到比较满意的表现。因此有了新的判断指标VQA-CP (VQA under Changing Priors)，这个数据集中训练集和测试集的QA分布不同，导致许多SOTA的VQA model在这个数据集中准确率都有显著的下降
当下流行一些基于集成(ensemble-based)的方法来减轻bias的影响，他们用question-only model来调整VQA model的训练过程，这些方法大致可以分为两类：
1.adversary-based：用对抗的方法训练两个model，最小化VQA model的损失的同时最大化question-only model的损失，两个model共享同一个question encoder，目标是学习一个bias-neutral的问题表示。然而，因为训练过程不稳定，因此产生了巨大的噪声
2.fusion-based：最后将两个model的答案分布结合起来，设计理念是让VQ ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/07/02/VQA/" title="VQA:数据集，算法和未来挑战 [综述]">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/VQA-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VQA:数据集，算法和未来挑战 [综述]"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/07/02/VQA/" title="VQA:数据集，算法和未来挑战 [综述]">VQA:数据集，算法和未来挑战 [综述]</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-07-02T10:40:08.000Z" title="发表于 2020-07-02 10:40:08">2020-07-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%93%9AVQA%E8%97%8F%E4%B9%A6%E9%98%81/">📚VQA藏书阁</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/VQA/">VQA</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/2017/">2017</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/">文献综述</a></span></div><div class="content">Paper Download Address
VQA(Visual Question Answering)是一个计算机视觉task，给定一个图片相关的问题和对应的图片，通过程序推断出答案
要求解决的问题是任意的，并且包含了诸多计算机视觉当中的子问题，比如

目标识别 (图中的物体是什么)
目标检测 (图中有猫么)
属性分类 (图中的猫是什么颜色的)
场景分类 (图中的天气是晴天么)
计数 (图中有几只猫)

当然除了这些，还有更多复杂的问题，比如目标的空间关系问题 (在沙发和猫之间的物体是什么)，常识推理问题 (图中的女孩为什么哭)
这是一篇2017年发表在Computer Vision and Image Understanding关于VQA的综述，文章内容包含以下几块

VQA与一些视觉和语言问题的对比
VQA当前可用的数据集以及优缺点
讨论VQA的评价指标
分析VQA已有的算法
讨论VQA未来的发展

VQA与其它视觉与语言任务的对比(这部分大致是我对这个章节的翻译，了解一下背景)
VQA的最终目标是从图片中获取问题相关的信息，根据问题，任务的范围可以从微小细节的检测到整张图片场 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/06/01/cinematography/" title="基于样例的相机行为控制器">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/cinematography-2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于样例的相机行为控制器"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/06/01/cinematography/" title="基于样例的相机行为控制器">基于样例的相机行为控制器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-06-01T20:32:56.000Z" title="发表于 2020-06-01 20:32:56">2020-06-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/SIGGRAPH/">SIGGRAPH</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/LSTM/">LSTM</a></span></div><div class="content">背景相机规划一直是虚拟现实领域一个活跃的讨论话题但相机行为(轨迹)的计算问题却甚少有人关注
已有用路径或者运动规划来指导相机轨迹的研究，主要受机器人学文献的启发
但大多数相机规划方法的关键实际上是描述何为好的运动(轨迹)
文章更倾向于从真实的电影片段中提取相机行为，文章在有限行为集上训练的深度学习网络，能够从真实的电影序列中提取相机行为，并利用对相机行为集合的先验学习将其重新定位到虚拟环境中
文章提出：基于样例的相机行为控制器
1.能够处理比单目标摄像更一般的情况(特别是电影中常见的双人交互)
2.通过从合成和真实电影剪辑中获得的一系列不同相机行为进行训练
3.自动从用户选择的电影片段中提取相机行为，投射到虚拟环境中
系统架构(1)a cinematic feature estimator
从电影剪辑中提取相关特征作为输入，在电影特征空间进行表示(输出)
(2)a gating network
通过low dimensional manifold学习，充当选择器
输入电影特征空间 (a path in the cinematic feature space)
输出为一系列相机行为，作为 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/04/10/WGAN/" title="Wasserstein GAN">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/ganpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Wasserstein GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/10/WGAN/" title="Wasserstein GAN">Wasserstein GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-10T18:13:06.000Z" title="发表于 2020-04-10 18:13:06">2020-04-10</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%8E%AAGAN%E9%A9%AC%E6%88%8F%E5%9B%A2/">🎪GAN马戏团</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/WGAN/">WGAN</a></span></div><div class="content">Wasserstein GAN希望采用Earth Mover Distance来取代JS-divergence，以解决GAN训练中梯度弥散和梯度不稳定的问题
首先是梯度弥散问题，生成器梯度弥散的原因是过分优秀的判别器，判别器越能准确的分辨$G$和$Data$，生成器梯度消失就越严重
对于最优参数的判别器，生成器Loss为
$C(G)=-log4+2D_{JS}(p_{data}||p_G)$
上式推导戳此处
最小化Loss就是最小化JS散度，具体在训练中就是尽量将$P_G$拉向$P_{data}$
JS divergence的问题就在于生成的数据和真实数据往往没有任何重叠，一是Data本质的问题，image在高维空间中的分布是一个低维的manifold，两者很难有overlap，其次在具体实现中Sampling使得overlap的概率更低
观察JS散度的表达式
$D_{JS}(P||Q)=\frac{1}{2}D_{KL}(P(x)||\frac{P(x)+Q(x)}{2})+\frac{1}{2}D_{KL}(Q(x)||\frac{P(x)+Q(x)}{2})$
$D_{KL}(P ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/03/fGAN/" title="fGAN--任意散度GAN">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/ganpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="fGAN--任意散度GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/03/fGAN/" title="fGAN--任意散度GAN">fGAN--任意散度GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-03T17:09:42.000Z" title="发表于 2020-04-03 17:09:42">2020-04-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%8E%AAGAN%E9%A9%AC%E6%88%8F%E5%9B%A2/">🎪GAN马戏团</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/fGAN/">fGAN</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/%E6%95%A3%E5%BA%A6/">散度</a></span></div><div class="content">fGAN的基本想法就是希望用不同的散度来取代JS散度
使得任何divergence都可以应用到GAN的框架中
f-divergence ：$D_f(P||Q) = \int_{x} q(x)f(\frac{p(x)}{q(x)})dx$
$f$函数需满足当$x=1$时 $f(x)=0$ 且$f$是$convex$
这个式子可以衡量分布P和Q的差异
若P分布和Q分布相同，则$D_f(P||Q) = \int_{x} f(1)dx=0$
当P分布与Q分布不同时，$D_f(P||Q) = \int_{x} q(x)f(\frac{p(x)}{q(x)})dx \ge f(\in_{x}q(x)\frac{p(x)}{q(x)}) =f(1) = 0$
(这里的积分大于等于是因为$f$是$convex$)
当$f(x)=xlogx$时
$D_f(P||Q)=\int_{x} \frac{p(x)}{q(x)} log(\frac{p(x)}{q(x)})=\int_{x} p(x)log(\frac{p(x)}{q(x)})=D_{KL}(P||Q)$
当$f(x)=-logx$时
$D_f( ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/03/27/CycleGAN1/" title="CycleGAN的隐写术">     <img class="post_bg" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/ganpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CycleGAN的隐写术"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/27/CycleGAN1/" title="CycleGAN的隐写术">CycleGAN的隐写术</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-27T18:02:36.000Z" title="发表于 2020-03-27 18:02:36">2020-03-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%F0%9F%8E%AAGAN%E9%A9%AC%E6%88%8F%E5%9B%A2/">🎪GAN马戏团</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CycleGAN/">CycleGAN</a></span></div><div class="content">(CycleGAN的介绍戳此处)
在CycleGAN的训练过程中
研究者发现，一张图片从Domain X到Domain Y的过程中可能会丢失了细节
但是令人惊讶的是，这张缺失细节的图从Domain Y映射回Domain X的时候这些细节又会被补全
也就是说CycleGAN在做Domain X到Domain Y的转化的时候隐藏了一些细节，使得我们肉眼无法观察到，但是其本身可以通过某些手段将这些记录的细节还原
用自适应直方图均衡化的手段可以观察到，CycleGAN学会了用低振幅高频信号的形式来隐藏原始图像中的细节信息，这种信号看起来几乎像是噪声，而利用这些信息，G可以再现原始图像，使得循环一致性的要求被满足
CycleGAN这种编码信息的特性很容易使得其遭受对抗性的攻击，攻击者可以通过干扰选定的原图像，使得Generator产生他们所选择的图像
文章作者认为CycleGAN模型的这种问题来自于循环一致性损失和Domain之间的熵差，因此改进的手段有修改循环一致性和添加额外的隐藏变量来人为地增加一个Domain的熵
比如在Cycle的时候引入噪声干扰信息编码等
不得不说CycleGAN利用信 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/7/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">forever97</div><div class="author-info__description">在人海里梦游</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">149</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">122</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/forever97"><i class="fab fa-github"></i><span>来给我加星星</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/forever97" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://gitee.com/forever97/" target="_blank" title="Gitee"><i class="fab fa-google"></i></a><a class="social-icon" href="https://www.cnblogs.com/forever97" target="_blank" title="博客园"><i class="fas fa-blog"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=857426255&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:857426255@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content"><h2 style="color:orange; margin:2px;">🍊欢迎光临本站</h2> 如果卡顿请访问 <a target="_blank" rel="noopener" href="https://forever97.gitee.io" style="cursor:pointer; color:#fff; background-color:orange; padding:2px 5px; border-radius:5px;">Gitee镜像站</a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/26/reactHooks/" title="React基础速通计划：React Hooks"><img data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/react.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="React基础速通计划：React Hooks"/></a><div class="content"><a class="title" href="/2022/06/26/reactHooks/" title="React基础速通计划：React Hooks">React基础速通计划：React Hooks</a><time datetime="2022-06-26T14:26:47.000Z" title="发表于 2022-06-26 14:26:47">2022-06-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/19/reactComponent/" title="React基础速通计划：React组件"><img data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/react.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="React基础速通计划：React组件"/></a><div class="content"><a class="title" href="/2022/06/19/reactComponent/" title="React基础速通计划：React组件">React基础速通计划：React组件</a><time datetime="2022-06-19T11:09:45.000Z" title="发表于 2022-06-19 11:09:45">2022-06-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/16/reactBasic/" title="React基础速通计划：React基础与JSX"><img data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/react.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="React基础速通计划：React基础与JSX"/></a><div class="content"><a class="title" href="/2022/06/16/reactBasic/" title="React基础速通计划：React基础与JSX">React基础速通计划：React基础与JSX</a><time datetime="2022-06-16T15:58:27.000Z" title="发表于 2022-06-16 15:58:27">2022-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/07/eventloop/" title="JS事件循环"><img data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/eventloop.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JS事件循环"/></a><div class="content"><a class="title" href="/2021/09/07/eventloop/" title="JS事件循环">JS事件循环</a><time datetime="2021-09-07T14:32:33.000Z" title="发表于 2021-09-07 14:32:33">2021-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/31/promise/" title="Promise详解"><img data-lazy-src="https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/promise.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Promise详解"/></a><div class="content"><a class="title" href="/2021/08/31/promise/" title="Promise详解">Promise详解</a><time datetime="2021-08-31T10:04:59.000Z" title="发表于 2021-08-31 10:04:59">2021-08-31</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E2%9C%A8%E9%A2%98%E8%A7%A3%E6%9D%82%E8%B4%A7%E9%93%BA/"><span class="card-category-list-name">✨题解杂货铺</span><span class="card-category-list-count">26</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E2%AD%90OD%E6%91%98%E6%98%9F%E6%A5%BC/"><span class="card-category-list-name">⭐OD摘星楼</span><span class="card-category-list-count">12</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8C%99VUE%E6%A2%A6%E5%B7%A5%E5%8E%82/"><span class="card-category-list-name">🌙VUE梦工厂</span><span class="card-category-list-count">15</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8C%BACSS%E8%8A%B1%E5%B8%82/"><span class="card-category-list-name">🌺CSS花市</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8D%AD%E7%AE%97%E6%B3%95%E5%B9%BC%E5%84%BF%E5%9B%AD/"><span class="card-category-list-name">🍭算法幼儿园</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8D%B0HTML%E7%82%B9%E5%BF%83%E9%93%BA/"><span class="card-category-list-name">🍰HTML点心铺</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8D%B5D3%E8%8C%B6%E6%A5%BC/"><span class="card-category-list-name">🍵D3茶楼</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%F0%9F%8D%BABLOG%E9%85%92%E8%82%86/"><span class="card-category-list-name">🍺BLOG酒肆</span><span class="card-category-list-count">2</span></a></li>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories/">
                <span>查看更多</span><i class="fas fa-angle-right"></i></a></li>
            </ul></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/06/"><span class="card-archive-list-date">六月 2022</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item more is-center"><a class="card-archive-list-link-more" href="/archives/">
              <span>查看更多</span><i class="fas fa-angle-right"  ></i></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">149</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2019-08-18T00:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">305.1k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-06-26T06:44:47.577Z"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://forever97-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/welcome-cover.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By forever97</div><div class="footer_custom_text"><p><a target="_blank" href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://demo.jerryc.me/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://metroui.org.ua/index.html "><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站托管于Vercel">&nbsp;<a target="_blank" href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "醉卧经阁半卷书&#44;坐井说天阔,纵使文章惊海里&#44;纸上苍生而已".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '醉卧经阁半卷书&#44;坐井说天阔'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/gitcalendar/js/gitcalendar.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/magnet/js/catalogMagnet.js"></script><script src="/swiper/swiper.min.js"></script><script src="/swiper/swiperindex.js"></script><script src="/js/moments.js"></script><script src="/js/smooth-scrolling.js"></script><script src="/js/custom.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div><!-- hexo injector body_end start --><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>未央の时光机</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='/'|| '/' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/33.2017.newyear.model.json"},"display":{"position":"right","width":200,"height":300},"mobile":{"show":false},"react":{"opacity":0.7}});</script></body></html>