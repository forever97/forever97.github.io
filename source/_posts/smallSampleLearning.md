---
title: 小样本学习
date: 2020-08-12 17:55:33
tags: [小样本学习, 元学习, 目标检测]
mathjax: true
cover: https://forever97.github.io/2020/10/19/Re0-1/4.png
---
记录一些小样本学习相关知识 (from 物体分类与检测中的小样本学习)

## 基本概念

小样本学习意义

1. 特定任务场景下标注代价高昂，小样本学习旨在探索以低成本的标注形式完成原本高质量大规模标注的数据集才能完成的任务
2. 数据具有长尾分布(long-tail distribution)的特点，数据集中一小部分类别经常出现，大量物体类别对应样本比较稀少，能否利用位于数据分布尾部的先验知识来辅助物体识别算法的训练，而不是简单地依赖这些很难获取到类别的少量样本进行监督学习训练，是很有研究意义和实用价值的

小样本(Small Sample Learning)的定义

1. 测试类别的训练样本完全缺失
2. 部分或者全部测试类别只有少量的训练样本
3. 部分或者全部测试类别训练样本标注信息粗糙，不完整

**物体分类**中的小样本学习：分为零样本学习，单样本/少样本学习和半监督学习

—— 零样本学习 (Zero-Shot Learning)

指训练集和测试集类别完全不同

零样本学习需要引入**额外的辅助信息**，辅助信息包含属性特征，物体的文本描述，以及在大型文本语料库上学习到的对应物体类别名称的词嵌入

—— 单样本/少样本学习 (One/Few-Shot Learning)

用**单张或者几张**训练图片来学习针对测试类别的分类器，**不需要辅助信息**的引入，测试集和支撑集(support set)的类别是相同的

—— 半监督学习 (Semi Supervised Learning)

半监督学习比少样本学习任务有更多的训练样本，同时，可以利用**大量无标注**的图片进行训练，即需要用少量有标注的数据和大量无标注的数据实现分类目标

**物体检测**中的小样本学习分为弱监督检测，半监督检测以及混合监督检测

![](1.png)

—— 弱监督检测 (Weakly Supervised Detection)

只进行类别标注

—— 半监督检测 (Semi Supervised Detection)

全部类别标注，部分位置标注

只有类别标注的记为弱标注数据，有全部标注的记为强标注数据

—— 混合监督检测 (Mixed Supervised Detection)

同时利用弱标注数据和强标注数据，和半监督检测的区别是弱标注数据和强标注数据的类别没有重叠

小样本学习的研究思路

—— 数据扩充

零样本学习：用产生式模型从测试类别的辅助信息中直接产生测试类别的训练样本

半监督分类：1. 用产生式模型从少量标注样本中学习模拟类别的数据分布，依照数据分布产生大量样本进行训练；2. 借助课程学习(Curriculum Learning)/自步学习(Self-Paced Learning)思想，用少量标注图片得到初始模型，利用初始模型给无标注图片打上伪标签，从简单图片到困难图片，将这些图片依次加入到算法流程中，和标注图片一起进行模型训练

—— 元学习 (Meta-Task Learning)

不直接去学习特定类别的算法模型，先学习类别无关(category-independent)的任务，同时要求这种类别无关的任务对最终的小样本目标识别是有帮助的

零样本：学习一个类别无关的"视觉-语义"投影

单样本/少样本：直接用于模型参数更新的任务，比如学习快速更新的初始化参数，直接学习某一层网络对应的参数

混合监督检测任务：学习分类器-检测器差异，学习一般性的物体性知识(objectness knowledge)等

## 小样本学习 

这部分内容主要是介绍零样本学习和混合监督检测

### 零样本学习

辅助信息的处理方式有

1. 将模糊的类别特征转化为精确的属性表达(量化的领域知识表达)，比如动物的食物来源(肉食/素食/杂食)

2. TF-IDF(Term Frequency-Inverse Document Frequency)处理为固定维度的特征表达，TF-IDF用于评估一个词对语料库的重要程度(和出现次数成正比，和出现频率成反比)，特征的维度是语料库中的词数，维度的具体数值是词在本段中的重要程度，那么类别相关的词，重要程度就会高，这种词往往代表了类别的特点

3. 词嵌入(word-embedding)，把每个类别对应的名字(word)投射到多维空间，保证是单射(injective)，同时有结构保持特点(structure-preserving)，词嵌入的计算方式有skip-gram，CBOW(continue bag-of-words)，以及GloVe(Global Vectors)，前两种采用局部邻域信息，GloVe是计算单词的全局频率信息，词向量要求：1.语义相似的单词词向量也相似；2.具有语义类比性质，Beijing - China = Paris - France

零样本学习方法

数据扩充：分为直接产生图片和直接产生图片特征两种

元学习：根据元任务的不同，零样本学习分为以下三类

(1) 元任务设置为属性分类器

首先在训练类别上训练一个类别无关的属性分类器，测试阶段测试图片对应的属性通过属性分类器直接获得，然后搜寻测试类别集合中拥有最近似属性的类别，实现分类

(2) 元任务设置为通用的嵌入空间

用通用的嵌入空间(embedding space)来联结每个类别对应的图片特征表达和辅助信息表达，首先在训练类别上学习视觉-语义空间，在测试阶段将测试图片的特征和各个测试类别的辅助信息同时映射到嵌入空间，通过比较嵌入空间图片的特征和各个测试类别辅助信息的距离远近，通过简单的最近邻搜索即可得到测试图片对应的类别预测

(3) 元任务设置为类别关系

首先学习测试类别和训练类别的关系，将测试类别看成是多个训练类别的线性组合，将训练类别上得到的分类器直接迁移到测试类别上

使用调和平均数的gZSL评价方法更贴近零样本学习的现实应用场景

### 混合监督检测

为解决标注代价高的问题，研究人员提出了弱监督(Weakly Supervised Detection)方法，只使用类别标签，推理物体的精确位置，但是效果不好，所以有了混合监督检测，做法是用一些类别的全标注数据，去提升新类别的弱监督检测能力

混合监督检测的基本思路是从全标注类别上学习某种对于检测有用的知识(比如物体性知识)，如果这种知识本身是类别无关的，则可以直接用到弱标注的类别上，如果是类别相关的，则需要继续进行类别关系学习这种元任务










