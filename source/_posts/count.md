---
title: Countæ¨¡å—æºç è§£è¯»
date: 2020-07-29 07:32:55
tags: [count, code, VQA, ICLR, 2018]
mathjax: true
categories: ğŸ“šVQAè—ä¹¦é˜
cover: /2020/07/29/count/5.png
---
[Code Download Address](https://github.com/Cyanogenoid/vqa-counting/blob/master/vqa-v2/counting.py)

[Paper Record](https://forever97.github.io/2020/07/28/1802-05766/)

è®¡æ•°çš„åŸºæœ¬æ–¹æ³•æ˜¯ç¡®å®šè¾¹çš„æ•°é‡ï¼Œé€šè¿‡å­å›¾å®Œå…¨å›¾è¾¹å’Œç‚¹çš„å…³ç³»æ¥è®¡ç®—ç‚¹æ•°ï¼Œæœ€åå¾—åˆ°ç­”æ¡ˆ

## top n bounding box

é¦–å…ˆå¤„ç†å‡ºå¤„ç†å‡ºtop nçš„æ³¨æ„åŠ›æƒé‡å’Œå¯¹åº”çš„bounding box

```python
def filter_most_important(self, n, boxes, attention):
    """ Only keep top-n object proposals, scored by attention weight """
    attention, idx = attention.topk(n, dim=1, sorted=False)
    idx = idx.unsqueeze(dim=1).expand(boxes.size(0), boxes.size(1), idx.size(1))
    boxes = boxes.gather(2, idx)
    return boxes, attention
```

boxesçš„shapeä¸º(n, 4, m)ï¼Œattentionçš„shapeä¸º(n, m)ï¼Œå…¶ä¸­nä¸ºbatch sizeï¼Œmä¸ºä¸€å¼ å›¾ä¸­bboxçš„æ•°é‡

```python
torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) â†’ (Tensor, LongTensor)
```

kè¡¨ç¤ºtop kï¼Œdimä¸ºæŒ‡å®šç»´åº¦ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™é»˜è®¤æœ€åä¸€ç»´ï¼Œlargestè¡¨ç¤ºè¿”å›æœ€å¤§è¿˜æ˜¯æœ€å°(True/False)ï¼Œsortedè¡¨ç¤ºè¿”å›çš„top kæ˜¯å¦éœ€è¦æ’åºï¼Œoutå¯é€‰è¾“å‡ºå¼ é‡(Tensor, LongTensor)

è¿”å›å€¼æ˜¯ä¸€ä¸ªå…ƒç»„(values,indices)

æºç ä¸­æŒ‡å®šçš„dim=1æ˜¯bboxç»´åº¦ï¼Œå³é€‰å–attentionæƒå€¼æœ€å¤§çš„kä¸ªbbox

```python
torch.unsqueeze(input, dim) â†’ Tensor
```

unsqueezeç”¨äºç»´åº¦æ‰©å……ï¼Œdimä¸ºæ’å…¥çš„ç»´åº¦ä¸‹æ ‡

expandæ˜¯å°†torchçš„å„ä¸ªç»´åº¦æ‰©å±•åˆ°æ›´å¤§çš„å°ºå¯¸ï¼Œåœ¨unsqueezeä¹‹åï¼Œidxå˜ä¸º(n,1,m)ï¼Œç„¶åæ‰©å±•ä¸º(n,4,m)ï¼Œå’Œbboxçš„tensorå°ºå¯¸ç›¸åŒ

```python
torch.gather(input, dim, index, out=None, sparse_grad=False) â†’ Tensor
```

gatherå‡½æ•°åœ¨dimç»´åº¦æŒ‰ç…§indexå¯¹inputè¿›è¡Œç´¢å¼•æŠŠå¯¹åº”çš„æ•°æ®æå–å‡ºæ¥çš„ï¼Œè¿™é‡Œæ˜¯æå–å‡ºtop kçš„attentionæƒå€¼å¯¹åº”çš„bbox

## Calculate A && D

ç„¶åè®¡ç®—æ³¨æ„çŸ©é˜µå’Œè·ç¦»çŸ©é˜µ

```python
relevancy = self.outer_product(attention)
distance = 1 - self.iou(boxes, boxes)
```

çœ‹ä¸‹çŸ©é˜µå¤–ç§¯(outer_produce)çš„å®ç°

```python
def outer(self, x):
    size = tuple(x.size()) + (x.size()[-1],)
    a = x.unsqueeze(dim=-1).expand(*size)
    b = x.unsqueeze(dim=-2).expand(*size)
    return a, b

def outer_product(self, x):
    # Y_ij = x_i * x_j
    a, b = self.outer(x)
    return a * b
```

(x.size()[-1],)è¡¨ç¤ºå°†x.size()çš„æœ€åä¸€ç»´å–å‡ºå¹¶å°†å…¶è¡¨ç¤ºä¸ºå…ƒç»„ï¼Œå…ƒç»„ç›¸åŠ æ˜¯æ‹¼æ¥è€ŒéæŒ‰ä½ç›¸åŠ ï¼Œå¾—åˆ°sizeä¸º(n,m,m)ï¼Œæ‰€ä»¥outerçš„ä½œç”¨å°±æ˜¯å°†xå˜æˆä¸¤ä¸ª(n,m,m)çš„tensorï¼Œå°†æƒå€¼æ”¾åœ¨å¯¹åº”çš„å€’æ•°ç¬¬ä¸€ç»´å’Œå€’æ•°ç¬¬äºŒç»´ï¼Œouter_productå°†xè½¬åŒ–åå¾—åˆ°çš„aå’Œbç›¸ä¹˜å¾—åˆ°å¤–ç§¯

çœ‹ä¸€ä¸‹Intersection over Union(IoU)çš„å®ç°

```python
def iou(self, a, b):
    # this is just the usual way to IoU from bounding boxes
    inter = self.intersection(a, b)
    area_a = self.area(a).unsqueeze(2).expand_as(inter)
    area_b = self.area(b).unsqueeze(1).expand_as(inter)
    return inter / (area_a + area_b - inter + 1e-12)
```

å…ˆçœ‹ä¸€ä¸‹ intersection

```python
def intersection(self, a, b):
    size = (a.size(0), 2, a.size(2), b.size(2))
    min_point = torch.max(
        a[:, :2, :].unsqueeze(dim=3).expand(*size),
        b[:, :2, :].unsqueeze(dim=2).expand(*size),
    )
    max_point = torch.min(
        a[:, 2:, :].unsqueeze(dim=3).expand(*size),
        b[:, 2:, :].unsqueeze(dim=2).expand(*size),
    )
    inter = (max_point - min_point).clamp(min=0)
    area = inter[:, 0, :, :] * inter[:, 1, :, :]
    return area
```

a[:, :2, :]è¡¨ç¤ºå°†dim=1çš„å‰ä¸¤ä¸ªåˆ‡ç‰‡(å·¦ä¸Šè§’åæ ‡)å–å‡ºï¼Œå¯¹åº”çš„a[:, 2:, :]åˆ™ä¸ºå³ä¸‹è§’åæ ‡

```python
torch.max(input, other, out=None) â†’ Tensor
```

torch.maxå¯ä»¥å°†å–ä¸¤ä¸ªtensorå¯¹åº”ä½ç½®çš„æœ€å¤§å€¼ï¼Œè¿”å›æ˜¯ä¸€ä¸ªtensorï¼Œä¸¤ä¸ªtensorä¸ä¸€æ ·å¤§æ—¶å¯ä»¥å¹¿æ’­è®¡ç®—ï¼Œä¸è¿‡è¿™é‡Œæºç ç›´æ¥å°†å…¶æ‹‰ä¼¸æˆä¸€æ ·å¤§çš„äº†

å°†å·¦ä¸Šè§’å–æœ€å¤§å€¼å°±å¾—åˆ°äº†ç›¸äº¤åŒºåŸŸçš„ä¸Šç•Œï¼ŒåŒç†ï¼Œå³ä¸‹è§’å–æœ€å°å€¼å¾—åˆ°äº†ç›¸äº¤åŒºåŸŸçš„ä¸‹ç•Œ

```python
torch.clamp(input, min, max, out=None) â†’ Tensor
```

clampç»™tensorçš„å…ƒç´ é™å®šä¸Šä¸‹ç•Œ(min,max)ï¼Œå¦‚æœä¸¤ä¸ªbboxæ²¡æœ‰äº¤é›†ï¼Œåˆ™å¯èƒ½è®¡ç®—å‡ºæ¥çš„æ˜¯è´Ÿæ•°ï¼Œæ‰€ä»¥éœ€è¦è®¾å®šä¸‹ç•Œ0ï¼Œå°†ä¸¤ä¸ªinterå¯¹åº”çš„é•¿å®½ç›¸ä¹˜å¾—åˆ°æ¯ä¸¤ä¸ªbboxçš„ç›¸äº¤é¢ç§¯areaï¼Œå¾—åˆ°é¢ç§¯äº¤çŸ©é˜µ

ç„¶åçœ‹ä¸€ä¸‹area

```python
def area(self, box):
    x = (box[:, 2, :] - box[:, 0, :]).clamp(min=0)
    y = (box[:, 3, :] - box[:, 1, :]).clamp(min=0)
    return x * y
```

æ˜¾ç„¶è®¡ç®—çš„æ˜¯bboxçš„é¢ç§¯ï¼ŒåŒæ—¶ç”¨äº†clampåšäº†æå°é™åˆ¶é˜²æ­¢å‡ºç°è´Ÿæ•°

åœ¨iouä¸­å°†å¾—åˆ°çš„areaé€šè¿‡unsqueezeåœ¨çŸ©é˜µä¸Šæ¨ªå‘æ‰©å±•å’Œçºµå‘æ‰©å±•ï¼Œç›¸åŠ å†å‡å»é¢ç§¯äº¤çŸ©é˜µå³å¯å¾—åˆ°é¢ç§¯å¹¶çŸ©é˜µï¼ŒIoU = é¢ç§¯äº¤/é¢ç§¯å¹¶ï¼Œè®¡ç®—å³å¯

ç„¶åç”¨å¾—åˆ°çš„æ³¨æ„åŠ›çŸ©é˜µAå’Œè·ç¦»çŸ©é˜µDå»è®¡ç®—$\bar{A}$

![](1.png)

## intra-object dedup

```python
score = self.f[0](relevancy) * self.f[1](distance)
```

å°†Aå’ŒDé€šè¿‡ä¸¤ä¸ªä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œç„¶åç‚¹ä¹˜æ¥æ¶ˆé™¤intra-object

æ¥çœ‹ä¸€ä¸‹æ¿€æ´»å‡½æ•°çš„å®ç°

åœ¨__init__é‡Œæœ‰

```python
 self.f = nn.ModuleList([PiecewiseLin(16) for _ in range(16)])
```

æŸ¥çœ‹ä½œè€…å†™çš„åˆ†æ®µçº¿æ€§å‡½æ•°PiecewiseLin

```python
class PiecewiseLin(nn.Module):
    def __init__(self, n):
        super().__init__()
        self.n = n
        self.weight = nn.Parameter(torch.ones(n + 1))
        # the first weight here is always 0 with a 0 gradient
        self.weight.data[0] = 0

    def forward(self, x):
        # all weights are positive -> function is monotonically increasing
        w = self.weight.abs()
        # make weights sum to one -> f(1) = 1
        w = w / w.sum()
        w = w.view([self.n + 1] + [1] * x.dim())
        # keep cumulative sum for O(1) time complexity
        csum = w.cumsum(dim=0)
        csum = csum.expand((self.n + 1,) + tuple(x.size()))
        w = w.expand_as(csum)

        # figure out which part of the function the input lies on
        y = self.n * x.unsqueeze(0)
        idx = Variable(y.long().data)
        f = y.frac()

        # contribution of the linear parts left of the input
        x = csum.gather(0, idx.clamp(max=self.n))
        # contribution within the linear segment the input falls into
        x = x + f * w.gather(0, (idx + 1).clamp(max=self.n))
        return x.squeeze(0)
```

cumsumæ˜¯ç´¯åŠ 

```python
torch.cumsum(input, dim, out=None, dtype=None) â†’ Tensor
```

è¿”å›çš„tensor yæ»¡è¶³$y_i=x_1+x_2+\dots+x_i$

é€šè¿‡w=w/w.sum()å’Œself.weight.data[0] = 0ä¿è¯$f_k(0)=0ï¼Œf_k(1)=1$

## inter-object dedup

ç„¶åæ¶ˆé™¤inter-objectï¼Œæ–¹æ³•æ˜¯ç­‰æ¯”ä¾‹ç¼©å°è¾¹çš„æƒé‡

![](2.png)

```python
dedup_score = self.f[3](relevancy) * self.f[4](distance)
dedup_per_entry, dedup_per_row = self.deduplicate(dedup_score, attention)
score = score / dedup_per_entry
```

![](3.png)

dedup_scoreå°±æ˜¯è®¡ç®—äº†å¼ä¸­çš„Xï¼Œ$X = f_4(A)\odot f_5(D)$

çœ‹ä¸€ä¸‹deduplicateå‡½æ•°

```python
def deduplicate(self, dedup_score, att):
    # using outer-diffs
    att_diff = self.outer_diff(att)
    score_diff = self.outer_diff(dedup_score)
    sim = self.f[2](1 - score_diff).prod(dim=1) * self.f[2](1 - att_diff)
    # similarity for each row
    row_sims = sim.sum(dim=2)
    # similarity for each entry
    all_sims = self.outer_product(row_sims)
    return all_sims, row_sims
```

å…¶ä¸­ç”¨äº†ä¸€ä¸ªouter_diffå‡½æ•°

```python
def outer_diff(self, x):
    # like outer products, except taking the absolute difference instead
    # Y_ij = | x_i - x_j |
    a, b = self.outer(x)
    return (a - b).abs()
```

å’Œouter_productçš„åŠŸèƒ½ç±»ä¼¼ï¼Œç”¨è¿™ä¸ªå‡½æ•°æ±‚äº†attentionçš„ä¸¤ä¸¤æƒé‡å·®å’Œdedup_scoreçš„ä¸¤ä¸¤å·®ï¼ŒæŒ‰ç…§å¼å­è®¡ç®—äº†proposalä¸¤ä¸¤ä¹‹é—´çš„ç›¸ä¼¼åº¦

```python
torch.prod(input, dim, keepdim=False, dtype=None) â†’ Tensor
```

prodæ˜¯å¯¹æŒ‡å®šç»´åº¦dimæ±‚å…ƒç´ ç§¯ï¼Œå¯¹åº”å…¬å¼ä¸­çš„$\prod$

$row\_sims$è®¡ç®—äº†proposal iå’Œå…¶å®ƒproposalç›¸ä¼¼çš„æ¬¡æ•°

å¯¹äº$edge_{ij}$æ¥è¯´å€¼éœ€è¦é™¤ä»¥${row\_sims}_i$å’Œ${row\_sims}_j$ï¼Œæ‰€ä»¥è¿™é‡Œå¤„ç†äº†$row\_sims$çš„$outer\_product$ï¼Œå³$all\_sims$

ç„¶åå¯¹scoreè¿›è¡Œäº†ç¼©æ”¾ï¼Œå³å¾—åˆ°äº†$\bar{A}\odot ss^T$

## aggregate the score

ç­”æ¡ˆç»Ÿè®¡ç”¨çš„æ˜¯$|V|=\sqrt{|E|}$ï¼Œå› æ­¤è¿˜éœ€è¦å°†åœ¨intra-object dedupä¸­æ¶ˆå»çš„è‡ªç¯åŠ å›æ¥

```python
correction = self.f[0](attention * attention) / dedup_per_row
score = score.sum(dim=2).sum(dim=1, keepdim=True) + correction.sum(dim=1, keepdim=True)
score = (score + 1e-20).sqrt()
one_hot = self.to_one_hot(score)
```

![](4.png)

ç®—è‡ªç¯ç›´æ¥attentionç‚¹ç§¯ç„¶åé™¤å€ç‡ï¼ŒçŸ©é˜µç‚¹ç§¯å¯¹äºè¾¹æƒå€¼æ˜¯çº¿æ€§å˜åŒ–ï¼Œæ‰€ä»¥ä¹˜sè€Œä¸æ˜¯ä¹˜$s\odot s$ï¼ŒåŸå¼ä¸­diagæ˜¯å°†æ•°å€¼å¡«å…¥å¯¹è§’çŸ©é˜µçš„å¯¹è§’çº¿ï¼Œå› ä¸ºä»£ç ä¸­æ˜¯ç›´æ¥è®¡æ•°æ‰€ä»¥ä¸éœ€è¦è¿™æ­¥æ“ä½œ

ç›´æ¥æ±‚å’Œå¾—åˆ°äº†|E|ï¼Œå¼€æ–¹å³å¯å¾—åˆ°|V|ï¼Œä¹Ÿå°±æ˜¯æ­£ç¡®çš„è®¡æ•°

å¹¶å°†ç­”æ¡ˆè½¬åŒ–ä¸ºç‰¹æ®Šçš„one-hotç¼–ç $o=[o_0,o_1,\dots,o_n]^T$

$o_i=max(0,1-|c-i|)$

è‹¥ç­”æ¡ˆä¸ºæ•´æ•°ï¼Œåˆ™one-hotç¼–ç ç»“æœä¸ºå¯¹åº”ç­”æ¡ˆä½ç½®ä¸º1ï¼Œå…¶ä½™ä½ç½®ä¸º0ï¼Œå¦åˆ™oå¯¹åº”ä¸¤ä¸ªone-hotç¼–ç çš„çº¿æ€§æ’å€¼

```python
def to_one_hot(self, scores):
    """ Turn a bunch of non-negative scalar values into a one-hot encoding.
    E.g. with self.objects = 3, 0 -> [1 0 0 0], 2.75 -> [0 0 0.25 0.75].
    """
    # sanity check, I don't think this ever does anything (it certainly shouldn't)
    scores = scores.clamp(min=0, max=self.objects)
    # compute only on the support
    i = scores.long().data
    f = scores.frac()
    # target_l is the one-hot if the score is rounded down
    # target_r is the one-hot if the score is rounded up
    target_l = scores.data.new(i.size(0), self.objects + 1).fill_(0)
    target_r = scores.data.new(i.size(0), self.objects + 1).fill_(0)

    target_l.scatter_(dim=1, index=i.clamp(max=self.objects), value=1)
    target_r.scatter_(dim=1, index=(i + 1).clamp(max=self.objects), value=1)
    # interpolate between these with the fractional part of the score
    return (1 - f) * Variable(target_l) + f * Variable(target_r)
```

æœ€åè€ƒè™‘å°½å¯èƒ½ç”¨Aå’ŒDçŸ©é˜µä¸­ä¸º1å’Œ0çš„æ•°å­—æ¥è®¡ç®—ç­”æ¡ˆï¼Œè®¡ç®—ä¸¤ä¸ªç½®ä¿¡ç³»æ•°ï¼Œç„¶åè¿”å›æœ€ç»ˆçš„è®¡æ•°ç‰¹å¾

```python
one_hot = self.to_one_hot(score)
att_conf = (self.f[5](attention) - 0.5).abs()
dist_conf = (self.f[6](distance) - 0.5).abs()
conf = self.f[7](att_conf.mean(dim=1, keepdim=True) + dist_conf.mean(dim=2).mean(dim=1, keepdim=True))
return one_hot * conf
```

