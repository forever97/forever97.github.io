---
title: VIS2019论文整理
date: 2020-10-21 09:09:26
tags: [VIS, 2019]
categories: 可视化论文阅读
mathjax: true
cover: https://forever97.github.io/2020/10/21/VIS2019/1.png
---

> [V] VAST，[I] InfoVis，[S] SciVis 

整理一下VIS2019的论文内容(Abstract为主)，随缘更新

---

## VIS Best Paper 

{% note default modern %}
**[V] FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1908.00681.pdf')

数据流可视化系统允许用户构建数据流图，数据流图由查询和可视化模块组成，以指定系统功能，从而实现灵活的可视化数据探索。然而，学习数据流图的使用带来的开销往往会阻碍用户。

基于此，文章设计了一个用于数据流可视化系统的自然语言界面——FlowSense，利用自然语言处理技术来协助数据流图的构造。FlowSense使用带有特殊话语标记和特殊话语占位符的语义分析器来推广到不同的数据集和数据流图。它明确地将已识别的数据集和图表特殊话语呈现给用户，用于数据流上下文感知。使用FlowSense，用户可以通过简单的英语，更方便地扩展和调整数据流图，文章通过一个案例研究，领域专家用一个真实世界的数据来分析问题以及一个正式的用户研究来评估FlowSense

{% note default modern %}
**[I] Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff**
{% endnote %}

[[PDF]](https://prism.ucalgary.ca/bitstream/handle/1880/110696/DataChanges_InfoVis2019_Preprint.pdf?sequence=1&isAllowed=y)

复杂的数据可视化设计项目通常需要具有不同可视化相关技能的人员之间的协作，例如，许多团队包括创建新的可视化设计的设计人员和实现结果可视化软件的开发人员，数据描述工具、可视化设计工具和开发平台之间的差距给致力于创建新的数据可视化的设计人员-开发团队带来了挑战，虽然商业交互设计工具通常支持设计人员和开发人员之间的协作，但创建数据可视化带来了一些当前工具所不支持的独特挑战，特别是，可视化设计人员必须描述和构建对底层数据的理解，然后指定布局、数据编码和其他数据驱动参数，这些参数将在许多不同的数据值之间保持稳定。在较大的团队中，设计人员还必须清楚地将这些映射及其依赖关系传达给开发人员、客户端和其他协作者

文章报告了对五个大型多学科可视化设计项目的观察和反思，并强调了设计规范和六个data-specific可视化挑战。这些挑战包括适应不断变化的数据、预测数据中的边缘情况、理解技术挑战、明确依赖数据的交互、通信数据映射，以及跨迭代保持数据映射的完整性。基于这些观察，揭示了未来用于原型设计、测试和交流数据驱动设计的工具的机会

{% note default modern %}
**[S] InSituNet: Deep Image Synthesis for Parameter Space Exploration of Ensemble Simulations**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1908.00407)

文章提出了一个基于深度学习的代理模型——InSituNet，支持参数空间探索的集成仿真，在现场可视化

由于I/O和存储的限制，现场可视化(在模拟时生成可视化)在处理大规模模拟中越来越流行。然而，由于无法获得原始模拟数据，现场可视化方法限制了事后勘探的灵活性，虽然已经提出了多种基于图像的方法来缓解这一限制，但这些方法缺乏探索仿真参数的能力

模型被设计为卷积回归模型，学习仿真和可视化参数与可视化结果的映射。使用训练好的模型，用户可以在各种可视化设置下为不同的仿真参数生成新的图像，从而能够深入分析底层集成仿真。通过定量和定性评价，文章证明了InSituNet在燃烧、宇宙学和海洋模拟中的有效性

---

## A Tour of VAST

{% note default modern %}
**[V] NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1904.09044)

在许多科学学科中，复杂的计算模型经常被设计用来模拟真实世界的物理现象。然而，这些仿真模型的计算成本往往非常高，并且涉及大量的仿真输入参数，在模型应用于真正的科学研究之前，需要对这些参数进行分析和适当的校准

文章提出了一个可视化的分析系统，以促进交互探索性分析高维输入参数空间的复杂酵母细胞极化模拟。该系统可以帮助设计仿真模型的计算生物学家通过修改参数值，直观地校准输入参数，并立即可视化预测的仿真结果，而不需要对每个实例运行原始的昂贵仿真，后端分析框架是一个基于神经网络的代理模型

文章工作展示了使用神经网络作为视觉分析替代模型的优势，利用训练过的网络对原始模拟进行交互参数敏感性分析，并使用神经网络的激活最大化框架推荐最佳参数配置，在训练过程中，进行了两个案例研究，将结果与原始模拟模型的结果以及之前由专家进行的参数分析结果进行了比较

{% note default modern %}
**[V] Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1905.03911)

降维(DR)经常用于分析和可视化高维数据，因为它提供了数据的良好的第一眼。然而，为了从数据中获得有用的见解来解释DR结果，还需要额外的分析工作，比如识别集群并理解它们的特征，虽然有许多自动方法(例如基于密度的聚类方法)来识别聚类，但仍然缺乏了解聚类特征的有效方法。一个聚类可以通过其特征值的分布来表征，当特性数量很大时，查看原始特性值并不是一项简单的任务

为了解决这一难题，作者团队提出了一种可视化分析方法，可以在DR结果中有效地突出集群的基本特征。为了提取基本特征，引入了一种增强的对比主成分分析(cPCA)方法。该方法称为ccPCA (PCA中的对比类簇)，可以计算每个特征对一个类簇和其他类簇之间对比的相对贡献。通过使用ccPCA，团队创建了一个交互式系统，其中包括集群特性贡献的可伸缩可视化。团队用案例研究采用了几个公开的数据集来证明了方法和系统的有效性

{% note default modern %}
**[V] The What-If Tool: Interactive Probing of Machine Learning Models**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1907.04135)

开发和部署机器学习(ML)系统的一个关键挑战是理解它们在广泛的输入范围内的性能，为了应对这一挑战，作者团队创建了What-IF工具，这是一个开源的应用程序，允许从业者使用最少的编码来探测、可视化和分析ML系统。该工具让从业者可以在假设的情况下测试性能，分析不同数据特性的重要性，并在多个模型和输入数据子集之间可视化模型行为。它还允许从业者根据多个ML公平性指标来度量系统。文章主要描述了该工具的设计，并报告不同组织的实际使用情况

{% note default modern %}
**[V] Understanding the Role of Alternatives in Data Analysis Practices**
{% endnote %}

[[PDF]](https://hal.telecom-paristech.fr/hal-02182349v2/document)

数据工作者是将执行数据分析活动作为日常工作的一部分，但不正式定义为数据科学家的人。他们来自不同的领域，经常需要探索各种假设和理论、各种数据源、算法、方法、工具和可视化设计。综合起来，称之为替代方案

为了更好地理解和描述替代方案在分析中的作用，作者团队对12名具有不同专业知识的数据工作者进行了半结构化的访谈，进行了四种类型的分析来理解：1.为什么数据工作者要探索替代方案；2.选择的不同概念，以及它们如何融入感知过程；3.围绕备选方案的高级流程；4.继承策略来产生、探索和管理这些替代方案

团队发现参与者的不同层次的领域和计算专业知识，使用不同工具的经验，以及在他们更广泛的背景下的协作，在他们如何探索这些替代方案中扮演了重要的角色。这些发现表明需要更多地关注对替代方案的更深理解，需要更好的工具来促进替代方案的探索、解释和管理

基于这些分析和发现，团队提出了一个基于参与者1)关注程度、2)抽象水平和3)分析过程的框架。文章展示了这个框架如何帮助理解数据工作者在分析中如何考虑这类替代方案，以及工具设计者如何创建工具来更好地支持它们

{% note default modern %}
**[V] VASABI: Doing User Behaviour Analytics through Interactive Visual Hierarchical User Profiles**
{% endnote %}

[[PDF]](https://openaccess.city.ac.uk/id/eprint/22591/8/)

用户行为分析(UBA)系统提供了复杂的模型，可以捕捉用户长期的行为，目的是识别不符合用户档案的欺诈行为。由于UBA模型的解释所面临的挑战，文章提出了一种可视化分析方法，以帮助分析人员在多个层次(即个体和群体层次)上获得对用户行为的全面理解

作者团队采用以用户为中心的方法来设计一个可视化的分析框架，支持对用户集合和他们在数字应用程序中进行的众多活动的分析。该框架的核心是层次化用户配置文件的概念，层次化用户配置文件是基于源自会话的特性而构建的，以及使用主题建模方法来总结和分层用户行为的用户任务

团队外部化了一系列的分析目标和任务，并通过与专家一起执行的用例来评估提出的方法。团队观察到，在交互式可视化层次用户档案的帮助下，分析人员能够有效地进行探索性和调查性分析，能够理解用户行为的特征，在评估可疑用户和活动的同时做出明智的决定

---

## Provocations

{% note default modern %}
**[I] Data by proxy – material traces as autographic visualizations**
{% endnote %}

[[PDF]](https://arxiv.org/pdf/1907.05454)

根据定义，信息可视化将自身限制在符号信息的领域。这篇文章讨论了为什么该领域还应该考虑数据形式的符号编码，包括物理痕迹和物质指标。这篇论文比较了物理痕迹和可视化，并描述了产生、揭示和解释它们的技术和可视化实践，通过对信息可视化与自动图形可视化逆向模型的对比，探讨了材料数据的设计原则。Autographic visualization解决了信息可视化的局限性，比如不能直接反映数据生成的实际情况。这两个模型之间的比较允许探索信息可视化背后的知识假设，并揭示与科学可视化和跟踪阅读的丰富历史的联系

本文首先讨论了数据可视化和相应现象之间的差距，然后研究了材料可视化如何弥合这一差距。它将自动图形可视化与范式(如数据物理化和索引可视化)结合在一起，并将其置于符号学、科学和技术研究(STS)和科学表征的历史等更广泛的理论文献中。本文的主要部分提出了一个用于自动图形可视化的基本设计词汇，并举例说明公民科学家如何在他们的展示中使用自动图形原则，这似乎违反了信息可视化的规范原则，但成功地实现了证据构建的其他修辞目的。最后，本文讨论了自动图形可视化的局限性，提出了痕迹感知的实证研究路线图，并对信息可视化和自动图形可视化技术的发展进行了思考

{% note default modern %}
**[I] Design by Immersion: A Transdisciplinary Approach to Problem-Driven Visualizations**
{% endnote %}

[[PDF]](http://openaccess.city.ac.uk/id/eprint/22491/1/hall_design_2019Postprint.pdf)

虽然以前的工作存在如何从问题驱动的可视化工作和设计研究中引导和传播见解，但是文献并没有解决如何在跨学科团队中以推进所有相关学科的方式实现这些目标

在文章中介绍并定义了一种新的方法论范式，即浸入式设计，它为问题驱动的可视化工作提供了另一种视角。通过可视化研究人员参与目标领域的工作(或领域专家参与可视化研究)，浸入式设计将跨学科的经验嵌入到可视化过程的中心

文章说明了通过沉浸式设计的过程是如何打开了一套多样的设计活动，这些设计活动可以根据合作、项目和目标的类型以不同的方式组合在一起。最后，文章讨论了沉浸式设计的挑战和潜在的陷阱

{% note default modern %}
**[I] Criteria for Rigor in Visualization Design Study**
{% endnote %}

[[PDF]](http://openaccess.city.ac.uk/id/eprint/22644/1/Criteria%20for%20Rigor%20in%20Visualization%20Design%20Study.pdf)

通过可视化设计研究，作者团队提出了一种新的研究视角，强调设计是一种探究的方法，通过它实现的广泛的知识贡献是多元的，主观的和社会构建的。从这个解释主义者的立场，团队探索了可视化设计研究的本质，并提出了六个严格的标准，建议根据可视化设计研究及其报告所提供信息的程度来建立和判断其严密性，反射性，丰富性，是似而非的，共鸣性和透明性

这一观点和标准是通过四年围绕社会科学、信息系统和设计知识的严谨性和本质的讨论而构建的。作者建议来自同源学科的方法来支持可视化研究人员在设计研究的规划、执行和报告过程中满足这些标准

通过一系列有意提出的问题，文章探讨了可视化设计研究的新视角的含义，得出的结论是，作为一门学科，可视化还不能很好地接受、培养并充分受益于设计研究的严格的、解释性的方法。文章提出的观点和标准旨在激发围绕可视化设计研究的本质和学科更广泛的基础的对话和辩论

{% note default modern %}
**[I] What is Interaction for Data Visualization?**
{% endnote %}

[[PDF]](https://hal.archives-ouvertes.fr/hal-02197062/document)

交互是数据可视化的基础，但是"交互"在可视化上下文中的含义是模糊和混乱的。作者认为，这种混淆是由于缺乏共识的定义。为了解决这个问题，文章从综合可视化社区的交互的包容性观点开始——包括来自信息可视化、可视化分析和科学可视化的见解，以及高级和初级可视化研究人员的输入

一旦这个观点形成，将看到交互是如何在人机交互(HCI)领域中定义的。通过提取可视化和人机交互中交互观点的共性和差异，作者合成了可视化交互的定义

本文的定义旨在成为一种思考工具，并激发新颖而大胆的交互设计实践。作者希望通过更好地理解可视化中的交互是什么，它可以是什么来丰富可视化系统中交互的质量，并增强用户的能力

{% note default modern %}
**[I] Why Authors Don’t Visualize Uncertainty**
{% endnote %}

[[PDF]](http://users.eecs.northwestern.edu/~jhullman/Value_of_Uncertainty_Vis_CR.pdf)

尽管已经有提出在数据中传达不确定性来源的技术，但在媒体文章、数据驱动的报告和消费者应用中，明确地呈现不确定性是例外而不是规则，这项工作考虑了，为什么如此之多的可视化作者选择不可视化不确定性，文章提供了一份可视化作者之间关于与不确定性沟通相关的实践、关联和态度的详细描述，这些研究来自于对90位经常为他人创建可视化的作者的调查结果，并采访了13位有影响力的可视化设计师。文章研究结果突出了作者所面临的挑战，并揭示了关于不确定性在可视化中所扮演角色的假设和不一致性 (这里写的作者指可视化作者而不是这篇文章的作者)

特别是，作者承认描述不确定性的价值与省略直接描述不确定性的规范之间出现了明显的矛盾。为了解释这一矛盾，文章中提出了一个视觉化交际中的不确定性省略的修辞模型

文章中还采用了一种正式的统计模型，即观众如何判断可视化信号的强度，以可视化为基础的传播，以论证不确定性传播必然会降低观众统计推断的自由度。最后，提出了关于不确定性沟通的可视化研究如何能够更好地服务从业者当前的需求和价值观，同时加深对强化不确定性遗漏的假设的理解的建议

---

## Scalar Topology

{% note default modern %}
**[S] Progressive Wasserstein Barycenters of Persistence Diagrams**
{% endnote %}

[[PDF]](https://julien-tierny.github.io/stuff/papers/vidal_vis19.pdf)

文章提出了一种有效的 持续图 瓦瑟斯坦重心(Wasserstein barycenters) 渐进逼近算法，并应用于集成数据的可视化分析。给定一组标量字段，文章的方法允许计算一个持久性图，该图代表该集合，并可视化地表达在该集合中发现的主要特性的数量、数据范围和显著性

团队重述了Wasserstein距离近似的有效算法，以扩展先前在重心估计方面的工作。提出了一种新的快速逼近质心的算法，该算法通过迭代递增计算精度和输出图中持久化特征的数量来逐步逼近质心。这样的累进性极大地提高了实践中的收敛性，并允许设计一个可中断的算法，能够尊重计算时间的限制，这使得交互时间内的Wasserstein重心近似成为可能。

本文介绍了一个集成聚类的应用程序，重新使用k-means算法来利用重心，并在执行时间限制内计算有意义的集成数据簇及其重心图。对合成数据集和现实生活中的数据集进行的广泛实验表明，该算法收敛于质心，这些质心在应用方面具有定性意义，在定量上与以前的技术相比较，同时提供了一个数量级的加速

{% note default modern %}
**[S] The Effect of Data Transformations on Scalar Field Topological Analysis of High-Order FEM Solutions**
{% endnote %}

[[PDF]](https://www.researchgate.net/profile/Ashok_Jallepalli/publication/334494490_The_Effect_of_Data_Transformations_on_Scalar_Field_Topological_Analysis_of_High-Order_FEM_Solutions/links/5d2e1391a6fdcc2462e62c3d/The-Effect-of-Data-Transformations-on-Scalar-Field-Topological-Analysis-of-High-Order-FEM-Solutions.pdf)

高阶有限元方法(HO-FEM)因其在求解复杂流动动力学方面的成功而在模拟界中越来越受欢迎。越来越需要分析这些模拟所产生的输出数据。
同时，拓扑分析工具正在成为研究模拟数据的强大方法，然而，由于两个原因，目前大多数拓扑分析方法在HO-FEM模拟数据中的应用有限：首先，当前的拓扑工具是为线性数据设计的(多项式度为1)，但是这些模拟输出的数据的多项式度通常较高(通常高达多项式度为6)，其次，模拟数据和模拟数据的导出量在单元边界处存在不连续，且这些不连续不符合拓扑工具的输入要求。解决这两个问题的一种方法是转换高阶数据，以实现拓扑分析的低阶连续输入。然而，很少有工作评估可能的转换选择及其对拓扑分析的下游影响

文章进行了一项实证研究，以评估两种常用的数据转换方法以及最近引入的L-SIAC滤波器用于处理高阶模拟数据。研究结果显示，不同的行为是可能的。文章中提供了一些指导，说明如何使用当前可用的拓扑分析实现最好地考虑HO-FEM模拟的拓扑分析管道

---

## VIS Meets Machine Learning

{% note default modern %}
**[V] GUIRO: User-Guided Matrix Reordering**
{% endnote %}

[[PDF]](https://vcg.seas.harvard.edu/publications/guiro-user-guided-matrix-reordering/paper)

矩阵表示是一种被实践证明是有效的关系可视化技术(或网络)数据。但是，如果母表(类似于节点链接图)的布局揭示了底层的数据拓扑，那么它们是最有效的，考虑到许多已开发的算法，一个实际的问题出现了:“我应该为我手边的数据集选择哪个矩阵重排序算法?”，更糟糕的是，对同一数据集应用不同的重排序算法可能会产生明显不同的视觉矩阵模式。这就导致了这些全自动的、通常是启发式的黑箱过程的可信赖性和可解释性的问题

基于此，文章提出了GUIRO，一个可视化的分析系统，它可以帮助新手、网络分析师和算法设计者打开黑箱。用户可以研究70种可达矩阵排序算法的实用性和表达性，对于网络分析师，文章中介绍了一种新的模型空间表示和两种交互技术，用于用户引导的行或列，特别是组的重排序(子矩阵重排序)，这些新技术有助于理解全局和局部数据集拓扑

作者通过让算法设计者访问16个重排序质量指标和可视化的探索方法来在行/列排列级别上比较重排序实现来支持算法设计者。并对GUIRO进行了12个主题的指导探索性用户研究，一个案例研究展示了它在真实场景中的有用性，并通过专家研究收集了对设计决策的反馈。文中提出的方法甚至可以帮助没有经验的用户理解矩阵模式，并允许用户引导重排序算法。GUIRO帮助增加矩阵重新排序算法的透明度，从而帮助广泛的用户更好地了解复杂的重排序过程，反过来支持数据和重排序算法的洞察力

{% note default modern %}
**[S] LassoNet: Deep Lasso-Selection of 3D Point Clouds**
{% endnote %}

[[PDF]](https://www.researchgate.net/profile/Wei_Zeng13/publication/335273831_LassoNet_Deep_Lasso-Selection_of_3D_Point_Clouds/links/5de7505d4585159aa45f7b25/LassoNet-Deep-Lasso-Selection-of-3D-Point-Clouds.pdf)

在三维点云的探索性分析和可视化中，选择是一个基本的任务。以往对选择方法的研究主要基于局部点密度等启发式方法，这限制了它们在一般数据中的适用性。具体的挑战根源于点云(例如，稠密与稀疏)、视点(例如，闭塞与非闭塞)和套索(例如，小与大)所隐含的巨大变化

文章引入了一种新的深度神经网络LassoNet来进行三维点云的lasso-selection，试图学习从视点和套索到点云区域的潜在映射。为此，通过三维坐标变换和朴素选择将用户目标点与视点和lasso信息结合起来，并通过意图滤波和最远点采样提高方法的可扩展性

作者使用在两个不同的点云数据上有超过30K个lasso-selection记录的数据集来训练一个分层网络。最后进行了一项正式的用户研究，以比较LassoNet与两种先进的lasso-selection方法。评估结果证实，文中的方法提高了不同组合的三维点云、视点和lasso-selection的选择效率和有效性

项目演示地址：https://lassonet.github.io/

{% note default modern %}
**[S] TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization**
{% endnote %}

[[PDF]](http://www.nd.edu/~cwang11/research/vis19-tsr.pdf)

文章提出了TSR-TVD，一个新的深度学习框架，使用对抗数据生成时间超分辨率(TSR)的时变数据(TVD)。TSR-TVD是第一个应用循环生成网络(RGN)的作品，它是循环神经网络(RNN)和生成对抗网络(GAN)的结合，从低分辨率的体积序列生成时间高分辨率的体积序列

TSR-TVD的设计包括一个生成器和一个鉴别器。生成器以一对体积作为输入，并通过前向和后向预测输出合成的中间体积序列。鉴别器以合成的中间体积作为输入，并产生一个分数来表示这些体积的真实度。这种方法也处理多元数据，其中一个变量的训练网络被用于为另一个变量生成TSR

为了证明TSR-TVD的有效性，文中展示了几个时变多元数据集的定量和定性结果，并将方法与仅基于RNN或CNN的标准线性插值和解决方案进行比较



